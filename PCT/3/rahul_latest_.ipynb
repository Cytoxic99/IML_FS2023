{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b5ba59af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2aaab7f8c090>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torchvision.transforms as tf\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "random.seed(100)\n",
    "np.random.seed(100)\n",
    "th.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7513f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "65724e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pretrained_model = tv.models.resnet152(pretrained=True)\n",
    "pretrained_model.eval()\n",
    "pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "778daa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "num_ftrs = pretrained_model.fc.in_features\n",
    "pretrained_model.fc = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9e7c71f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_path = '../handouts/food/'\n",
    "feature_path = '../handouts/features/'\n",
    "\n",
    "os.makedirs(feature_path, exist_ok=True)\n",
    "\n",
    "def extract_features():\n",
    "    \n",
    "    transforms = tf.Compose([\n",
    "        tf.Resize(256),\n",
    "        tf.ToTensor(),\n",
    "        tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "    \n",
    "    for image_path in tqdm(glob(food_path +'*.jpg')):\n",
    "        curr_image = Image.open(image_path)\n",
    "        curr_image_transformed = transforms(curr_image).to(device)\n",
    "        curr_image_extracted = pretrained_model(curr_image_transformed.unsqueeze(0))[0]\n",
    "        \n",
    "        feature_path_name = feature_path + Path(image_path).name[:-4] + '.pt'\n",
    "        th.save(curr_image_extracted.cpu(), feature_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d851d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8e216b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "\n",
    "def load(item):\n",
    "    if item in cache:\n",
    "        return cache[item]\n",
    "    else:\n",
    "        cache[item] = th.load(feature_path + item + '.pt')\n",
    "        return cache[item]\n",
    "        \n",
    "class MyDataset:\n",
    "    def __init__(self, triplet_data):\n",
    "        self.triplet_data = triplet_data\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        A, B, C = self.triplet_data[i]\n",
    "        \n",
    "        A_img = load(A)\n",
    "        B_img = load(B)\n",
    "        C_img = load(C)\n",
    "        \n",
    "        return th.stack([A_img, B_img, C_img])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.triplet_data)\n",
    "    \n",
    "def getTriplets(path):\n",
    "    triplets = []\n",
    "    for line in open(path):\n",
    "        A, B, C = line.split()\n",
    "        triplets.append((A, B, C))\n",
    "    return triplets\n",
    "\n",
    "class MyDatasetTrain:\n",
    "    def __init__(self, triplet_data):\n",
    "        self.triplet_data = triplet_data\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        A, B, C = self.triplet_data[i]\n",
    "        \n",
    "        A_img = load(A)\n",
    "        B_img = load(B)\n",
    "        C_img = load(C)\n",
    "        \n",
    "        order = np.random.randint(0,2)\n",
    "        if order == 0:\n",
    "            return order, th.stack([A_img, B_img, C_img])\n",
    "        else:\n",
    "            return order, th.stack([A_img, C_img, B_img])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.triplet_data)\n",
    "\n",
    "train_triplets = getTriplets('../handouts/train_triplets.txt')\n",
    "test_triplets = getTriplets('../handouts/test_triplets.txt')\n",
    "\n",
    "random.shuffle(train_triplets)\n",
    "val_size =  1024 \n",
    "train_size = len(train_triplets) - val_size\n",
    "\n",
    "training_dataset = MyDatasetTrain(train_triplets)\n",
    "train_set, val_set = th.utils.data.random_split(training_dataset, [train_size, val_size], generator=th.manual_seed(100))\n",
    "test_dataset = MyDataset(test_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3c36c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 256),\n",
    "    nn.CELU(alpha=1),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.Dropout(0.75),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.CELU(alpha=1),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.Dropout(0.15),\n",
    "    nn.Linear(128, 128),\n",
    ").to(device)\n",
    "\n",
    "optim = th.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c1cd5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(train_set, batch_size=256, shuffle=True, pin_memory=True, generator=th.manual_seed(100))\n",
    "validation_loader = DataLoader(val_set, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a2f4bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    \n",
    "    errors = total = 0\n",
    "    \n",
    "    for lab, batch in loader:\n",
    "        x = batch.view((3 * batch.shape[0], batch.shape[2])).to(device)\n",
    "        y = model(x).view((batch.shape[0], batch.shape[1], -1))\n",
    "\n",
    "        y_ordered = th.zeros_like(y)\n",
    "        y_ordered[:,0,:] = y[:,0,:]\n",
    "        lab_inv_mat = ((1 - lab).repeat(y.shape[2],1)).transpose(0,1).to(device)\n",
    "        lab_mat = (lab.repeat(y.shape[2],1)).transpose(0,1).to(device)\n",
    "        y_ordered[:, 1, :] = lab_inv_mat * y[:, 1, :] + lab_mat * y[:, 2, :]\n",
    "        y_ordered[:, 2, :] = lab_inv_mat * y[:, 2, :] + lab_mat * y[:, 1, :]\n",
    "\n",
    "        first_similar = th.linalg.norm(y_ordered[:,0,:] - y_ordered[:,1,:], dim=1)\n",
    "        second_similar = th.linalg.norm(y_ordered[:,0,:] - y_ordered[:,2,:], dim=1)\n",
    "\n",
    "        total += first_similar.shape[0]\n",
    "        errors += (first_similar >= second_similar).sum().item()\n",
    "\n",
    "    return errors / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5647dc2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization error 0.4121\n",
      "Current training error 0.260638388811954\n",
      "epoch 0 error 0.2461 in 8.6 seconds\n",
      "Current training error 0.25017524063531144\n",
      "epoch 1 error 0.2480 in 8.6 seconds\n",
      "Current training error 0.23516438426424577\n",
      "epoch 2 error 0.2256 in 8.3 seconds\n",
      "Current training error 0.228787334803645\n",
      "epoch 3 error 0.2109 in 8.4 seconds\n",
      "Current training error 0.2229573780581628\n",
      "epoch 4 error 0.2188 in 8.8 seconds\n",
      "Current training error 0.21716161460737549\n",
      "epoch 5 error 0.2148 in 9.0 seconds\n",
      "Current training error 0.20695491614094477\n",
      "epoch 6 error 0.2041 in 8.5 seconds\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "error = evaluate(model, validation_loader)\n",
    "print('initialization error', \"{:.4f}\".format(error))\n",
    "\n",
    "import time\n",
    "for epoch in range(8):\n",
    "    \n",
    "    start = time.time()\n",
    "    model.train()\n",
    "\n",
    "    for lab, data in training_loader:\n",
    "        x = data.view((3 * data.shape[0], data.shape[2])).to(device)\n",
    "        y = model(x).view((data.shape[0], data.shape[1], -1))\n",
    "\n",
    "        y_ordered = th.zeros_like(y)\n",
    "        y_ordered[:,0,:] = y[:,0,:]\n",
    "        lab_inv_mat = ((1 - lab).repeat(y.shape[2],1)).transpose(0,1).to(device)\n",
    "        lab_mat = (lab.repeat(y.shape[2],1)).transpose(0,1).to(device)\n",
    "        \n",
    "        y_ordered[:, 1, :] = lab_inv_mat * y[:, 1, :] + lab_mat * y[:, 2, :]\n",
    "        y_ordered[:, 2, :] = lab_inv_mat * y[:, 2, :] + lab_mat * y[:, 1, :]\n",
    "        \n",
    "        loss = F.triplet_margin_loss(y_ordered[:,0,:], y_ordered[:,1,:], y_ordered[:,2,:], margin=1.0)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    model.eval()\n",
    "    error = evaluate(model, validation_loader)\n",
    "    val_error = evaluate(model, training_loader)\n",
    "    print(\"Current training error\", val_error)\n",
    "    print(\"epoch\", epoch, \"error\", \"{:.4f}\".format(error), \"in\", \"{:.1f}\".format(time.time() - start), \"seconds\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "37a502cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4b560df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model, loader):\n",
    "    \n",
    "    model.eval()\n",
    "    batch = next(iter(loader))\n",
    "    x = batch.view((3 * batch.shape[0], batch.shape[2])).to(device)\n",
    "    y = model(x).view((batch.shape[0], batch.shape[1], -1))\n",
    "    \n",
    "    first_similar = th.linalg.norm(y[:,0,:] - y[:,1,:], dim=1)\n",
    "    second_similar = th.linalg.norm(y[:,0,:] - y[:,2,:], dim=1)\n",
    "    \n",
    "    guesses = (first_similar < second_similar)\n",
    "    \n",
    "    return guesses.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2755eebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_results(model, test_loader)\n",
    "result_array = result.cpu().numpy()\n",
    "\n",
    "# decent_submission = np.loadtxt('decent_submission.txt')\n",
    "\n",
    "# print(np.sum(np.abs(result_array - decent_submission)) / result_array.shape[0])\n",
    "np.savetxt('submission.txt', result.cpu().numpy(), fmt='%i')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
